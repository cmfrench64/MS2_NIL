{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from urllib.parse import urljoin\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Attempt just using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = ['college', 'high-school']\n",
    "sports = ['football', 'basketball', 'baseball', 'womens-basketball', 'volleyball', 'gymnastics',\n",
    "         'mens-lacrosse', 'womens-lacrosse', 'mens-soccer', 'womens-soccer', 'softball', 'womens-track',\n",
    "         'mens-golf', 'womens-golf', 'mens-hockey', 'womens-hockey', 'mens-swimming', 'womens-swimming']\n",
    "\n",
    "all_names = []\n",
    "\n",
    "for level in levels:\n",
    "    for sport in sports:\n",
    "\n",
    "        URL = f'https://www.on3.com/nil/rankings/player/{level}/{sport}/'\n",
    "\n",
    "        page = requests.get(URL)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        results = soup.find(class_=\"NilRankingsPageComponent_nilRankingsList__t14Ao\")\n",
    "\n",
    "        try:\n",
    "            names_sport = results.find_all('a', class_=\"MuiTypography-root MuiLink-root MuiLink-underlineNone MuiTypography-h5 MuiTypography-colorPrimary\")\n",
    "            for name in names_sport:\n",
    "                all_names.append(name)\n",
    "        except:\n",
    "            # print(\"Whoops! No athletes appear to have NIL deal for {} {}\".format(level, sport))\n",
    "            continue\n",
    "    #end\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414\n"
     ]
    }
   ],
   "source": [
    "print(len(all_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there were only 414 athletes using this section of the On3 database... This is such a small number of athletes that we should investiage looking at different sections of the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Selenium & Beatuiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n",
      "Isaiah Collier 18 2023 - present\n"
     ]
    }
   ],
   "source": [
    "sports = ['basketball']\n",
    "#years = ['2022','2023','2024','2025','2026']\n",
    "years = ['2023']\n",
    "\n",
    "ages = []\n",
    "athlete_grade = []\n",
    "\n",
    "for year in years:\n",
    "    for sport in sports:\n",
    "        \n",
    "        # Selenium Driver to click on \"Load More\"\n",
    "        driver = webdriver.Chrome()\n",
    "        URL = f'https://www.on3.com/db/rankings/industry-player/{sport}/{year}/'\n",
    "        driver.get(URL)\n",
    "        \n",
    "        # while True:\n",
    "        #     try:\n",
    "        #         load_more_button = WebDriverWait(driver, 10).until(\n",
    "        #             EC.element_to_be_clickable((By.XPATH, \"//span[@class='MuiButton-label' and contains(text(), 'Load More')]\"))\n",
    "        #         )\n",
    "        #         load_more_button.click()\n",
    "        #         time.sleep(10)\n",
    "        #     except:\n",
    "        #         break\n",
    "        \n",
    "        # Beautiful Soup - for each player\n",
    "        page_source = driver.page_source\n",
    "        page_soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        results = page_soup.find(class_=\"PlayerRankings_playerRankings__jvfFg\")\n",
    "\n",
    "        athletes = results.find_all('a', class_=\"MuiTypography-root MuiLink-root MuiLink-underlineHover MuiTypography-h5 MuiTypography-colorPrimary\")\n",
    "        # It is possible that two athletes have the same name: John Smith\n",
    "        # We cannot use a dictionary so a list of tuples is used for now\n",
    "        names = [athlete.text for athlete in athletes]\n",
    "\n",
    "        # Generate a list of links that we can iterate through\n",
    "        links = [athlete['href'] for athlete in athletes]\n",
    "        base_url = \"https://www.on3.com/\"\n",
    "        athlete_links = [urljoin(base_url, link) for link in links]\n",
    "\n",
    "        for athlete_link in athlete_links:\n",
    "            # We can now go into each individual athletes page\n",
    "            # for that sport, for that year, after loading more\n",
    "            driver.get(athlete_link)\n",
    "            time.sleep(3)\n",
    "\n",
    "            athlete_source = driver.page_source\n",
    "            page_soup = BeautifulSoup(athlete_source, 'html.parser')\n",
    "\n",
    "            if page_soup.find(class_=\"MuiTypography-root CollegeRanking_span__qtAfW MuiTypography-subtitle1 MuiTypography-colorPrimary\") is not None:\n",
    "                age = page_soup.find(class_=\"MuiTypography-root CollegeRanking_span__qtAfW MuiTypography-subtitle1 MuiTypography-colorPrimary\")\n",
    "                ages.append(age.text)\n",
    "            else:\n",
    "                ages.append(np.nan)\n",
    "            \n",
    "            # The \"EXP\" class_name folows the exact same class_name as \"Year\"...\n",
    "            if page_soup.find(class_=\"MuiTypography-root CollegeRanking_span__qtAfW MuiTypography-subtitle1 MuiTypography-colorTextPrimary\") is not None:\n",
    "                year_ = page_soup.find(class_=\"MuiTypography-root CollegeRanking_span__qtAfW MuiTypography-subtitle1 MuiTypography-colorTextPrimary\")\n",
    "                athlete_grade.append(year_.text)\n",
    "            else:\n",
    "                athlete_grade.append(np.nan)\n",
    "        #end\n",
    "        print(len(names), len(ages), len(athlete_grade))\n",
    "        print(names[0], ages[0], athlete_grade[0])\n",
    "    #end\n",
    "#end\n",
    "\n",
    "        # This successfully takes us back to the previous page, but it might require us to reload every athlete...\n",
    "        # driver.back()\n",
    "        # url = driver.current_url\n",
    "        # print(url)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Isaiah Collier\n"
     ]
    }
   ],
   "source": [
    "print(len(names))\n",
    "print(names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sports = ['basketball']\n",
    "# #years = ['2022','2023','2024','2025','2026']\n",
    "# years = ['2023']\n",
    "\n",
    "\n",
    "# urls = {}\n",
    "\n",
    "# for year in years:\n",
    "#     for sport in sports:\n",
    "\n",
    "        \n",
    "            \n",
    "        # page = requests.get(URL)\n",
    "        # soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        #results = soup.find(class_=\"PlayerRankings_playerRankings__jvfFg\")\n",
    "        \n",
    "        # page_soup = soup(driver.page_source, 'html.parser')\n",
    "        # print(page_soup)\n",
    "        # results = page_soup.find(class_=\"PlayerRankings_playerRankings__jvfFg\")\n",
    "        # try:\n",
    "        #     names_sport = results.find_all('a', class_=\"MuiTypography-root MuiLink-root MuiLink-underlineHover MuiTypography-h5 MuiTypography-colorPrimary\")\n",
    "        #     for name in names_sport:\n",
    "        #         urls[name.text] = name['href']\n",
    "        # except:\n",
    "        #     print(\"Whoops! No athletes appear to have NIL deal for {} {}\".format(level, sport))\n",
    "        #     continue\n",
    "    #end\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_info = {}\n",
    "\n",
    "# for name, url in urls.items():\n",
    "#     all_info[name] = []\n",
    "#     URL = f'https://www.on3.com{url}/recruiting'\n",
    "#     page = requests.get(URL)\n",
    "#     soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    \n",
    "    \n",
    "#     results = soup.find(class_=\"PlayerRecruiting_playergrid__wYlb_\")\n",
    "#     player_info = results.find_all('span', class_=\"MuiTypography-root MeasurementInfo_text__dCryI MuiTypography-body1 MuiTypography-colorTextPrimary\")\n",
    "#     for info in player_info:\n",
    "#         all_info[name].append(info.text)\n",
    "    \n",
    "#     results = soup.find(class_=\"Rankings_container__U2afk\")\n",
    "#     rankings_info = results.find_all('p', class_=\"MuiTypography-root Rankings_industryRating__9uavm MuiTypography-body1 MuiTypography-colorTextPrimary\")\n",
    "#     for info in rankings_info:\n",
    "#         all_info[name].append(info.text)\n",
    "    \n",
    "    \n",
    "#     results = soup.find(class_=\"PlayerInterestsModule_targets__rxz4U\")\n",
    "#     recruitment_info = results.find_all(['a','h6'], class_=[\"MuiTypography-root MuiLink-root MuiLink-underlineNone PlayerInterestsItem_teamName__FeBHv MuiTypography-h5 MuiTypography-colorPrimary\",\"MuiTypography-root PlayerInterestsItem_predictionLabel__mT201 MuiTypography-subtitle1 MuiTypography-colorTextPrimary\"])\n",
    "#     for info in  recruitment_info:\n",
    "#         all_info[name].append(info.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
