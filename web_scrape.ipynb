{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from urllib.parse import urljoin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Selenium & Beatuiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully recovered 326 athletes for basketball 2023!\n",
      "========== Starting Scrape ===========\n",
      "!!!! ENTERING THE RECRUIT COLLEGES LOOP FOR ATHLETE Isaiah Collier !!!!\n",
      "!!!! APPENDING THE STAR COLLEGE FOR ATHLETE Isaiah Collier\n",
      "colleges was appended successfully\n",
      "college_distance was appended successfully\n",
      "!!!! ENTERING THE RECRUIT COLLEGES LOOP FOR ATHLETE Justin Edwards !!!!\n",
      "!!!! APPENDING THE STAR COLLEGE FOR ATHLETE Justin Edwards\n",
      "colleges was appended successfully\n",
      "college_distance was appended successfully\n",
      "!!!! ENTERING THE RECRUIT COLLEGES LOOP FOR ATHLETE Ron Holland !!!!\n",
      "!!!! APPENDING THE STAR COLLEGE FOR ATHLETE Ron Holland\n",
      "colleges was appended successfully\n",
      "college_distance was appended successfully\n",
      "!!!! ENTERING THE RECRUIT COLLEGES LOOP FOR ATHLETE Aaron Bradshaw !!!!\n",
      "!!!! APPENDING THE STAR COLLEGE FOR ATHLETE Aaron Bradshaw\n",
      "colleges was appended successfully\n",
      "college_distance was appended successfully\n",
      "!!!! ENTERING THE RECRUIT COLLEGES LOOP FOR ATHLETE Matas Buzelis !!!!\n",
      "!!!! APPENDING THE STAR COLLEGE FOR ATHLETE Matas Buzelis\n",
      "colleges was appended successfully\n",
      "college_distance was appended successfully\n",
      "!!!! ENTERING THE RECRUIT COLLEGES LOOP FOR ATHLETE Cody Williams !!!!\n",
      "!!!! APPENDING THE STAR COLLEGE FOR ATHLETE Cody Williams\n",
      "colleges was appended successfully\n",
      "college_distance was appended successfully\n",
      "all_team_link page is not loading for athlete DJ Wagner Jr.\n",
      "!!!! APPENDING NAN TO THE COLLEGES FOR ATHLETE DJ Wagner Jr. !!!!\n",
      "all_team_link page is not loading for athlete Stephon Castle\n",
      "!!!! APPENDING NAN TO THE COLLEGES FOR ATHLETE Stephon Castle !!!!\n",
      "!!!! ENTERING THE RECRUIT COLLEGES LOOP FOR ATHLETE Ja'Kobe Walter !!!!\n",
      "!!!! APPENDING THE STAR COLLEGE FOR ATHLETE Ja'Kobe Walter\n",
      "colleges was appended successfully\n",
      "college_distance was appended successfully\n",
      "NIL page not loading for athlete Ja'Kobe Walter\n",
      "Player page not loading for athlete Omaha Biliew\n",
      "Player page not loading for athlete Jared McCain\n",
      "Player page not loading for athlete Mackenzie Mgbako\n",
      "Player page not loading for athlete Elliot Cadeau\n",
      "Player page not loading for athlete Xavier Booker\n",
      "Player page not loading for athlete Robert Dillingham\n",
      "Player page not loading for athlete Kwame Evans Jr.\n",
      "Player page not loading for athlete Sean Stewart\n",
      "Player page not loading for athlete Aden Holloway\n",
      "Player page not loading for athlete TJ Power\n",
      "Player page not loading for athlete Caleb Foster\n",
      "Player page not loading for athlete Jarin Stevenson\n",
      "Player page not loading for athlete Elmarko Jackson\n",
      "Player page not loading for athlete AJ Johnson\n",
      "Player page not loading for athlete Andrej Stojakovic\n",
      "Player page not loading for athlete Bronny James\n",
      "Player page not loading for athlete Jackson Shelstad\n",
      "Player page not loading for athlete Trentyn Flowers\n",
      "Player page not loading for athlete Dennis Evans\n",
      "Player page not loading for athlete Yves Missi\n",
      "Player page not loading for athlete Dink Pate\n",
      "Player page not loading for athlete Baye Fall\n",
      "Player page not loading for athlete Coen Carr\n",
      "Player page not loading for athlete Mookie Cook\n",
      "Player page not loading for athlete Bryson Warren\n",
      "Player page not loading for athlete DeShawn Harris-Smith\n",
      "Player page not loading for athlete Dedan Thomas\n",
      "Player page not loading for athlete Simeon Wilcher\n",
      "Player page not loading for athlete Reed Sheppard\n",
      "Player page not loading for athlete Taison Chatman\n",
      "Player page not loading for athlete Garwey Dual\n",
      "Player page not loading for athlete Jeremy Fears\n",
      "Player page not loading for athlete Devin Royal\n",
      "Player page not loading for athlete Gavin Griffiths\n",
      "Player page not loading for athlete Brandon Garrison\n",
      "Player page not loading for athlete Milan Momcilovic\n",
      "Player page not loading for athlete Layden Blocker\n",
      "Player page not loading for athlete Solomon Ball\n",
      "Player page not loading for athlete Dusty Stromer\n",
      "Player page not loading for athlete Miro Little\n",
      "Player page not loading for athlete Kanaan Carlyle\n",
      "Player page not loading for athlete Wesley Yates\n",
      "Player page not loading for athlete Mikey Williams\n",
      "Player page not loading for athlete Chris Johnson\n",
      "Player page not loading for athlete Scotty Middleton\n",
      "Player page not loading for athlete Cameron Carr\n",
      "Player page not loading for athlete Eric Dailey\n",
      "Player page not loading for athlete Arrinten Page\n",
      "Player page not loading for athlete Elijah Gertrude\n",
      "Player page not loading for athlete Carey Booth\n",
      "Player page not loading for athlete JP Estrella\n",
      "Player page not loading for athlete Jaylin Stewart\n",
      "Player page not loading for athlete Sebastian Mack\n",
      "Player page not loading for athlete Amani Hansberry\n",
      "Player page not loading for athlete Zayden High\n",
      "Player page not loading for athlete Kaden Cooper\n",
      "Player page not loading for athlete Marcus Adams Jr.\n",
      "Player page not loading for athlete Blue Cain\n",
      "Player page not loading for athlete Dai Dai Ames\n",
      "Player page not loading for athlete Sam Walters\n",
      "Player page not loading for athlete Taylor Bol Bowen\n",
      "Player page not loading for athlete Trey Green\n",
      "Player page not loading for athlete Devin Williams\n",
      "Player page not loading for athlete Joseph Tugler\n",
      "Player page not loading for athlete Jizzle James\n",
      "Player page not loading for athlete Jamie Kaiser\n",
      "Player page not loading for athlete Silas Demary Jr.\n",
      "Player page not loading for athlete Jayden Ross\n",
      "Player page not loading for athlete Myles Colvin\n",
      "Player page not loading for athlete Blake Buchanan\n",
      "Player page not loading for athlete Kaleb Glenn\n",
      "Player page not loading for athlete Rayvon Griffith\n",
      "Player page not loading for athlete KJ Lewis\n",
      "Player page not loading for athlete Gehrig Normand\n",
      "Player page not loading for athlete Ilane Fibleuil\n",
      "Player page not loading for athlete Papa Kante\n",
      "Player page not loading for athlete Dailyn Swain\n",
      "Player page not loading for athlete Ty-Laur Johnson\n",
      "Player page not loading for athlete RJ Jones\n",
      "Player page not loading for athlete Dylan James\n",
      "Player page not loading for athlete Jaland Lowe\n",
      "Player page not loading for athlete Brandon Williams\n",
      "Player page not loading for athlete Jordan Butler\n",
      "Player page not loading for athlete Pryce Sandfort\n",
      "Player page not loading for athlete JJ Taylor\n",
      "Player page not loading for athlete Curtis Williams Jr.\n",
      "Player page not loading for athlete Rashaud Marshall\n",
      "Player page not loading for athlete Jacob McFarland\n",
      "Player page not loading for athlete Carlton Carrington\n",
      "Player page not loading for athlete Tre Norman\n",
      "Player page not loading for athlete Jamari McDowell\n",
      "Player page not loading for athlete Mouhamed Dioubate\n",
      "Player page not loading for athlete Dennis Parker\n",
      "Player page not loading for athlete Gabe Cupps\n",
      "Player page not loading for athlete Collin Murray-Boyles\n",
      "Player page not loading for athlete Corey Chest\n",
      "Player page not loading for athlete Trent Pierce\n",
      "Player page not loading for athlete Kris Parker\n",
      "Player page not loading for athlete Brandon Gardner\n",
      "Player page not loading for athlete Reid Ducharme\n",
      "Player page not loading for athlete Josh Hubbard\n",
      "Player page not loading for athlete Jace Posey\n",
      "Player page not loading for athlete Nils Cooper\n",
      "Player page not loading for athlete Isaiah Coleman\n",
      "Player page not loading for athlete Gus Yalden\n",
      "Player page not loading for athlete Drew Fielder\n",
      "Player page not loading for athlete Nolan Winter\n",
      "Player page not loading for athlete Alex Toohey\n",
      "Player page not loading for athlete Macaleab Rich\n",
      "Player page not loading for athlete Dra Gibbs-Lawhorn\n",
      "Player page not loading for athlete Cameron Christie\n",
      "Player page not loading for athlete Michael Nwoko\n",
      "Player page not loading for athlete Dramane Camara\n",
      "Player page not loading for athlete Jacolb Cole\n",
      "Player page not loading for athlete Assane Diop\n",
      "Player page not loading for athlete Jakai Newton\n",
      "Player page not loading for athlete JT Rock\n",
      "Player page not loading for athlete George Washington III\n",
      "Player page not loading for athlete Ashton Hardaway\n",
      "Player page not loading for athlete Parker Friedrichsen\n",
      "Player page not loading for athlete Justin McBride\n",
      "Player page not loading for athlete Zaide Lowery\n",
      "Player page not loading for athlete Jazz Gardner\n",
      "Player page not loading for athlete Jelani Hamilton\n",
      "Player page not loading for athlete Tru Washington\n",
      "Player page not loading for athlete Finley Bizjack\n",
      "Player page not loading for athlete Jahnathan Lamothe\n",
      "=== Scraped 100.0 % of the Players ===\n",
      "======================================\n",
      "Successfully completed 326 athletes for basketball 2023!\n",
      "Number of removed athletes: 0\n"
     ]
    }
   ],
   "source": [
    "sports = ['basketball']\n",
    "#years = ['2022','2023','2024','2025','2026']\n",
    "years = ['2022']\n",
    "\n",
    "exp = []\n",
    "athlete_grade = []\n",
    "pos_height_weight = []\n",
    "ages = []\n",
    "ranks = []\n",
    "high_school = []\n",
    "home_town = []\n",
    "colleges = []\n",
    "college_distance = []\n",
    "num_offers = []\n",
    "NIL_val = []\n",
    "instagram_followers = []\n",
    "twitter_followers = []\n",
    "tiktok_followers = []\n",
    "\n",
    "for year in years:\n",
    "    for sport in sports:\n",
    "        # Selenium Driver to click on \"Load More\"\n",
    "        driver = webdriver.Chrome()\n",
    "        URL = f'https://www.on3.com/db/rankings/industry-player/{sport}/{year}/'\n",
    "        driver.get(URL)\n",
    "\n",
    "        dummyCount = 0\n",
    "        ###########################################################################################################################\n",
    "        # Click the \"Load More\" button such that all athelete links are visible\n",
    "        # dummyCount was implemented for sports/years in which the number of athletes is very big (ex: football 2023 has 3000+ athletes) AND\n",
    "        # the 'Load More' button does not disappear when pressed to completiion... so a simple counter was implemented\n",
    "        # By making this condition: 'dummyCount < 19' we max out at 1000 athletes\n",
    "        while (dummyCount < 60):\n",
    "            try:\n",
    "                load_more_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//span[@class='MuiButton-label' and contains(text(), 'Load More')]\"))\n",
    "                )\n",
    "                load_more_button.click()\n",
    "                time.sleep(12)\n",
    "                dummyCount += 1\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        ###########################################################################################################################\n",
    "        \n",
    "        ###########################################################################################################################\n",
    "        # Get all athlete names & associated links\n",
    "        # New Information: names, links\n",
    "        page_source = driver.page_source\n",
    "        page_soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        results = page_soup.find(class_=\"PlayerRankings_playerRankings__jvfFg\")\n",
    "\n",
    "        athletes = results.find_all('a', class_=\"MuiTypography-root MuiLink-root MuiLink-underlineHover MuiTypography-h5 MuiTypography-colorPrimary\")\n",
    "        names = [athlete.text for athlete in athletes]\n",
    "        names_ = names\n",
    "\n",
    "        # Generate a list of links that we can iterate through\n",
    "        links = [athlete['href'] for athlete in athletes]\n",
    "        base_url = \"https://www.on3.com/\"\n",
    "        athlete_links = [urljoin(base_url, link) for link in links]\n",
    "\n",
    "        tot = len(athlete_links)\n",
    "\n",
    "        print('Successfully recovered {} athletes for {} {}!'.format(tot, sport, year))\n",
    "        print('========== Starting Scrape ===========')\n",
    "\n",
    "        ###########################################################################################################################\n",
    "\n",
    "        for i, athlete_link in enumerate(athlete_links):\n",
    "\n",
    "            ###########################################################################################################################\n",
    "            # Information from the \"Player\" page for each of the athletes\n",
    "            # New Information: exp, athlete_grade, ages, high_school, home_town, pos_height_weight\n",
    "            try:\n",
    "                driver.get(athlete_link)\n",
    "                time.sleep(3)\n",
    "\n",
    "                athlete_source = driver.page_source\n",
    "                page_soup = BeautifulSoup(athlete_source, 'html.parser')\n",
    "            except:\n",
    "                print(\"Player page not loading for athlete {}\".format(names_[i]))\n",
    "                exp.append(np.nan)\n",
    "                athlete_grade.append(np.nan)\n",
    "                pos_height_weight.append(np.nan)\n",
    "                ages.append(np.nan)\n",
    "                ranks.append(np.nan)\n",
    "                high_school.append(np.nan)\n",
    "                home_town.append(np.nan)\n",
    "                colleges.append(np.nan)\n",
    "                college_distance.append(np.nan)\n",
    "                num_offers.append(np.nan)\n",
    "                NIL_val.append(np.nan)\n",
    "                instagram_followers.append(np.nan)\n",
    "                twitter_followers.append(np.nan)\n",
    "                tiktok_followers.append(np.nan)\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                CollegeRankingInfo = page_soup.find(class_='CollegeRanking_info__LM3nn')\n",
    "\n",
    "                if CollegeRankingInfo:\n",
    "                    exp_year = CollegeRankingInfo.find_all(class_='MuiTypography-root CollegeRanking_span__qtAfW MuiTypography-subtitle1 MuiTypography-colorTextPrimary')\n",
    "                    if len(exp_year) == 2:\n",
    "                        exp.append(exp_year[0].text)\n",
    "                        athlete_grade.append(exp_year[1].text)\n",
    "                    else:\n",
    "                        exp.append(np.nan)\n",
    "                        athlete_grade.append(np.nan)\n",
    "                    age = CollegeRankingInfo.find(class_='MuiTypography-root CollegeRanking_span__qtAfW MuiTypography-subtitle1 MuiTypography-colorPrimary')\n",
    "                    ages.append(age.text)\n",
    "                else:\n",
    "                    exp.append(np.nan)\n",
    "                    athlete_grade.append(np.nan)\n",
    "                    ages.append(np.nan)\n",
    "            except:\n",
    "                print(\"exp, athlete_grade, age not available for athlete {}\".format(names_[i]))\n",
    "                exp.append(np.nan)\n",
    "                athlete_grade.append(np.nan)\n",
    "                ages.append(np.nan)\n",
    "            \n",
    "            try:\n",
    "                RecruitModuleInfo = page_soup.find(class_='RecruitModule_info__Ugxqd')\n",
    "\n",
    "                if RecruitModuleInfo:\n",
    "                    homeInfo = RecruitModuleInfo.find_all(class_='MuiTypography-root RecruitModule_span__KmmzN MuiTypography-subtitle1 MuiTypography-colorTextPrimary')\n",
    "                    high_school.append(homeInfo[-2].text)\n",
    "                    home_town.append(homeInfo[-1].text)\n",
    "                else:\n",
    "                    high_school.append(np.nan)\n",
    "                    home_town.append(np.nan)\n",
    "            except:\n",
    "                print(\"high_school, home_town not available for athlete {}\".format(names_[i]))\n",
    "                high_school.append(np.nan)\n",
    "                home_town.append(np.nan)\n",
    "\n",
    "            try:\n",
    "                Attributes = page_soup.find(class_='MeasurementInfo_info__IHmGD')\n",
    "\n",
    "                if Attributes:\n",
    "                    dummy = Attributes.find_all(class_='MuiTypography-root MeasurementInfo_text__dCryI MuiTypography-body1 MuiTypography-colorTextPrimary')\n",
    "                    pos_height_weight.append(dummy[1].text)\n",
    "                else:\n",
    "                    pos_height_weight.append(np.nan)\n",
    "            except:\n",
    "                print(\"pos_height_weight not available for athlete {}\".format(names_[i]))\n",
    "                pos_height_weight.append(np.nan)\n",
    "            ###########################################################################################################################\n",
    "            \n",
    "            ###########################################################################################################################\n",
    "            # Information from the \"Recruiting\" page for each of the athletes\n",
    "            # New Information: ranks, colleges (the college this athlete is targeting), college_distance, num_offers\n",
    "            try:\n",
    "                driver.get(urljoin(athlete_link,'recruiting/'))\n",
    "                time.sleep(3)\n",
    "                athlete_source = driver.page_source\n",
    "                page_soup = BeautifulSoup(athlete_source, 'html.parser')\n",
    "\n",
    "            except:\n",
    "                print(\"Recruiting page not loading for athlete {}\".format(names_[i]))\n",
    "                ranks.append(np.nan)\n",
    "                colleges.append(np.nan)\n",
    "                college_distance.append(np.nan)\n",
    "                num_offers.append(np.nan)\n",
    "                NIL_val.append(np.nan)\n",
    "                instagram_followers.append(np.nan)\n",
    "                twitter_followers.append(np.nan)\n",
    "                tiktok_followers.append(np.nan)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                Ranks = page_soup.find(class_=\"Rankings_industryRankWrapper__2qwnq\")\n",
    "\n",
    "                if Ranks:\n",
    "                    ranking = Ranks.find(class_=\"MuiTypography-root Rankings_industryRating__9uavm MuiTypography-body1 MuiTypography-colorTextPrimary\")\n",
    "                    ranks.append(ranking.text)\n",
    "                else:\n",
    "                    ranks.append(np.nan)\n",
    "            except:\n",
    "                print(\"ranks not available for athlete {}\".format(names_[i]))\n",
    "                ranks.append(np.nan)\n",
    "\n",
    "            try:\n",
    "                # Find url for all teams and navigate to page\n",
    "                all_team_link = page_soup.find(class_='MuiTypography-root MuiLink-root MuiLink-underlineHover PlayerInterestsModule_text__kjqNU MuiTypography-caption MuiTypography-colorPrimary')\n",
    "                driver.get(urljoin(base_url,all_team_link['href']))\n",
    "                time.sleep(5)\n",
    "                athlete_source = driver.page_source\n",
    "                page_soup = BeautifulSoup(athlete_source, 'html.parser')\n",
    "            \n",
    "            except:\n",
    "                print(\"all_team_link page is not loading for athlete {}\".format(names_[i]))\n",
    "                colleges.append(np.nan)\n",
    "                college_distance.append(np.nan)\n",
    "                num_offers.append(np.nan)\n",
    "                NIL_val.append(np.nan)\n",
    "                instagram_followers.append(np.nan)\n",
    "                twitter_followers.append(np.nan)\n",
    "                tiktok_followers.append(np.nan)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "\n",
    "                RecruitColleges = page_soup.find_all(class_='PlayerInterestsItem_teamContainer__vjQkf')\n",
    "\n",
    "                if RecruitColleges:\n",
    "                    count = 0\n",
    "                    for college in RecruitColleges:\n",
    "                        college_name = college.find(class_='MuiTypography-root MuiLink-root MuiLink-underlineNone PlayerInterestsItem_teamName__FeBHv MuiTypography-h5 MuiTypography-colorPrimary')\n",
    "                        college_dist = college.find(class_='MuiTypography-root PlayerInterestsItem_distanceText__KJhj3 MuiTypography-caption MuiTypography-colorTextPrimary')\n",
    "\n",
    "                        if count == 0:\n",
    "                            colleges.append(college_name.text)\n",
    "                            college_distance.append(college_dist.text)\n",
    "                        count +=1\n",
    "                    num_offers.append(count)\n",
    "                else:\n",
    "                    colleges.append(np.nan)\n",
    "                    college_distance.append(np.nan)\n",
    "                    num_offers.append(np.nan)\n",
    "            except:\n",
    "                print(\"colleges, college_distance, num_offers are not available for athlete {}\".format(names_[i]))\n",
    "                colleges.append(np.nan)\n",
    "                college_distance.append(np.nan)\n",
    "                num_offers.append(np.nan)\n",
    "            ###########################################################################################################################\n",
    "            \n",
    "            ###########################################################################################################################\n",
    "            # Information from the \"NIL\" page for each of the athletes\n",
    "            # New Information: NIL_val, instagram_followers, twitter_followers, tiktok_followers\n",
    "            try:\n",
    "                driver.get(urljoin(athlete_link,'nil/'))\n",
    "                time.sleep(3)\n",
    "                athlete_source = driver.page_source\n",
    "                page_soup = BeautifulSoup(athlete_source, 'html.parser')\n",
    "            \n",
    "            except:\n",
    "                print(\"NIL page not loading for athlete {}\".format(names_[i]))\n",
    "                NIL_val.append(np.nan)\n",
    "                instagram_followers.append(np.nan)\n",
    "                twitter_followers.append(np.nan)\n",
    "                tiktok_followers.append(np.nan)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                RecruitNIL = page_soup.find(class_='NilValuationCircle_nilCircleValue__wzomB')\n",
    "\n",
    "                if RecruitNIL:\n",
    "                    NIL_val.append(RecruitNIL.text)\n",
    "                else:\n",
    "                    NIL_val.append(np.nan)\n",
    "            except:\n",
    "                print(\"NIL_val not available for athlete {}\".format(names_[i]))\n",
    "                NIL_val.append(np.nan)\n",
    "            \n",
    "            try:\n",
    "                RecruitSocials = page_soup.find(class_=\"NilSocialValuations_socialValuations__MeR7O\")\n",
    "\n",
    "                instagram = np.nan\n",
    "                twitter = np.nan\n",
    "                tiktok = np.nan\n",
    "\n",
    "                if RecruitSocials:\n",
    "                    socials = RecruitSocials.find_all(class_=\"NilSocialValuations_platform__3qBMy\")\n",
    "                    for social in socials:\n",
    "                        social_name = social.find('a')['href']\n",
    "                        if 'instagram' in social_name:\n",
    "                            instagram = social.find(class_='MuiTypography-root NilSocialValuations_platformFollowers__sW8kK MuiTypography-body1 MuiTypography-colorTextPrimary').text\n",
    "                        elif 'twitter' in social_name:\n",
    "                            twitter = social.find(class_='MuiTypography-root NilSocialValuations_platformFollowers__sW8kK MuiTypography-body1 MuiTypography-colorTextPrimary').text\n",
    "                        elif 'tiktok' in social_name:\n",
    "                            tiktok = social.find(class_='MuiTypography-root NilSocialValuations_platformFollowers__sW8kK MuiTypography-body1 MuiTypography-colorTextPrimary').text\n",
    "                \n",
    "                instagram_followers.append(instagram)\n",
    "                twitter_followers.append(twitter)\n",
    "                tiktok_followers.append(tiktok)\n",
    "            \n",
    "            except:\n",
    "                print(\"insta, twitter, and tiktok followers not available for athlete {}\".format(names_[i]))\n",
    "                instagram_followers.append(np.nan)\n",
    "                twitter_followers.append(np.nan)\n",
    "                tiktok_followers.append(np.nan)\n",
    "            ###########################################################################################################################\n",
    "\n",
    "            ###########################################################################################################################\n",
    "            # Print something out to the user, like a progress bar\n",
    "            if (i % 10 == 0) and (i != 0):\n",
    "                print(\"=== Scraped {:.2f} % of the Players ===\".format((i/tot)*100))\n",
    "                print(len(names), len(exp), len(pos_height_weight), len(athlete_grade), len(ages), len(ranks), len(high_school), len(home_town),\n",
    "                      len(colleges), len(college_distance), len(num_offers), len(NIL_val),\n",
    "                      len(instagram_followers), len(twitter_followers),len(tiktok_followers))\n",
    "                print(\"======================================\")\n",
    "            ###########################################################################################################################\n",
    "        \n",
    "        print(\"=== Scraped 100.0 % of the Players ===\")\n",
    "        print(len(names), len(exp), len(pos_height_weight), len(athlete_grade), len(ages), len(ranks), len(high_school), len(home_town),\n",
    "              len(colleges), len(college_distance), len(num_offers), len(NIL_val),\n",
    "              len(instagram_followers), len(twitter_followers),len(tiktok_followers))\n",
    "        print(\"======================================\")\n",
    "        print('Successfully completed {} athletes for {} {}!'.format(len(names), sport, year))\n",
    "        #end\n",
    "    #end\n",
    "#end\n",
    "\n",
    "# Close the instance of the webpage\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50\n"
     ]
    }
   ],
   "source": [
    "print(len(names), len(exp), len(pos_height_weight), len(athlete_grade), len(ages), len(ranks), len(high_school), len(home_town),\n",
    "      len(colleges), len(college_distance), len(num_offers), len(NIL_val),\n",
    "      len(instagram_followers), len(twitter_followers),len(tiktok_followers))\n",
    "# print(names[0], exp[0], pos_height_weight[0], athlete_grade[0], ages[0], ranks[0], high_school[0])\n",
    "# print(home_town[0], colleges[0], college_distance[0], num_offers[0])\n",
    "# print(NIL_val[0], instagram_followers[0], twitter_followers[0], tiktok_followers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv saved to 'csv_files' folder!'\n"
     ]
    }
   ],
   "source": [
    "column_names = ['NAME', 'EXP', 'POS_HEI_WEI', 'GRADE', 'AGE', 'SKILL', 'HISCH', 'HOTOWN', 'STARCOLL', 'COLLDIST', 'NUMOFF', 'INSTA', 'TWIT', 'TIK', 'NILVAL']\n",
    "\n",
    "csv_file_path = 'csv_files/{}_{}.csv'.format(sport, year)\n",
    "\n",
    "with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    \n",
    "    writer.writerow(column_names)\n",
    "\n",
    "    for row in zip(names, exp, pos_height_weight, athlete_grade, ages, ranks, high_school, home_town, colleges, college_distance, num_offers, instagram_followers, twitter_followers, tiktok_followers, NIL_val):\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"csv saved to 'csv_files' folder!'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
