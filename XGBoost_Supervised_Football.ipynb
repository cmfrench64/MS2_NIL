{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost\n",
    "# pip install hyperopt\n",
    "#https://hyperopt.github.io/hyperopt/?source=post_page\n",
    "# pip install category_encoders\n",
    "# pip install scikit-optimize\n",
    "# pip install dtreeviz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numba.core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-24b79541d625>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_importance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kakib\\anaconda3\\lib\\site-packages\\shap\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# explainers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_explainer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExplainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kernel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKernel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mKernelExplainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSampling\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mSamplingExplainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kakib\\anaconda3\\lib\\site-packages\\shap\\explainers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_additive\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdditive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_deep\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_exact\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_gpu_tree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGPUTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linear\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kakib\\anaconda3\\lib\\site-packages\\shap\\explainers\\_additive.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMaskedModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe_isinstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_explainer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExplainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kakib\\anaconda3\\lib\\site-packages\\shap\\explainers\\_explainer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexplainers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaskers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_explanation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExplanation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_serializable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeserializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSerializable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSerializer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kakib\\anaconda3\\lib\\site-packages\\shap\\maskers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_fixed\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFixed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_fixed_composite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFixedComposite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_image\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_masker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMasker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_output_composite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOutputComposite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kakib\\anaconda3\\lib\\site-packages\\shap\\maskers\\_image.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnjit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNumbaPendingDeprecationWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_serializable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeserializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSerializer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numba.core'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBRegressor, plot_importance, plot_tree, plotting\n",
    "\n",
    "\n",
    "import dtreeviz\n",
    "import graphviz\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats as stats\n",
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "\n",
    "\n",
    "\n",
    "# #for hyperparameter tuning\n",
    "# import hyperopt\n",
    "# from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dataset (football_cleaned_supervised.csv)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data):\n",
    "    df = pd.read_csv(data)\n",
    "   \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_football= load_dataset('cleaned_files/football_clean_supervised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_football.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save athlete names for later indexing\n",
    "athlete_names = df_football['NAME']\n",
    "# athlete_names\n",
    "\n",
    "#remove Unnamed:0 and Sport column- not necessary \n",
    "def drop_col(df):\n",
    "    df=df.drop(columns=['Unnamed: 0', 'NAME', 'STARCOLL', 'institution_name_short','SPORT'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_football = drop_col(df_football)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_football.isna().sum()\n",
    "df_football.columns\n",
    "# df_football.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract target and features. Perform Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract target and features\n",
    "Target = 'NILVAL_LONG_USD'\n",
    "Predictors = ['GRADE', 'AGE', 'SKILL', 'NUMOFF', 'POS', 'HEIGHT_IN', 'WEIGHT_LBS',\n",
    "       'COLLDIST_MI', 'INSTA_LONG', 'TWIT_LONG', 'TIK_LONG',\n",
    "       'TOT_FOL', 'RECRUIT_YEAR', 'EXP_MONTHS', 'EXP_YEARS',\n",
    "       'ClassificationCode', 'REV_MEN', 'EXP_MEN']\n",
    "\n",
    "X = df_football.drop('NILVAL_LONG_USD', axis=1).values\n",
    "y =  df_football[['NILVAL_LONG_USD']].values\n",
    "# X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "#Shuffle data given concern that dataset has athletes ordered by SKILL (but also look at skew later based on model performance)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoostRegressor Base Model Decision Trees as Base Learners- using all features- using scikit learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using default parameters, boosting rounds = 5  objective =reg:squarederror  XGBoost default is gbtree\n",
    "xg_reg2 = XGBRegressor(n_estimators=5, random_state= 42)\n",
    "xg_reg2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test set: preds\n",
    "preds = xg_reg2.predict(X_test)\n",
    "\n",
    "# compute the rmse: rmse\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    " \n",
    "#Measuring Goodness of fit in Training data\n",
    "from sklearn import metrics\n",
    "print('Train R2 Value:',metrics.r2_score(y_train, xg_reg2.predict(X_train)))\n",
    " \n",
    "#Measuring accuracy on Testing Data\n",
    "print('Accuracy Test',100- (np.mean(np.abs((y_test - preds) / y_test)) * 100))\n",
    "\n",
    "\n",
    "\n",
    "#Plotting the feature importance for Top 10 most important columns\n",
    "%matplotlib inline\n",
    "feature_importances = pd.Series(xg_reg2.feature_importances_, index=Predictors)\n",
    "feature_importances.nlargest(10).plot(kind='barh')\n",
    "plt.xlabel (\"Feature Importance\")\n",
    "plt.title(\"Top 10 Most Important Features - XGBoost Regressor Model (GBtree)\")\n",
    " \n",
    "#Printing some sample values of prediction\n",
    "TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\n",
    "TestingDataResults[Target]=y_test\n",
    "TestingDataResults[('Predicted'+Target)]=preds\n",
    "TestingDataResults.head()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test, preds)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-31eafd0fe7c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "metrics.classification_report(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/parrt/dtreeviz/blob/master/notebooks/dtreeviz_xgboost_visualisations.ipynb\n",
    "\n",
    "#initialize dtreevizmodel (adaptor)\n",
    "\n",
    "viz_rmodel = dtreeviz.model(model=xg_reg2, tree_index=1, \n",
    "                            X_train=df_football[Predictors],\n",
    "                            y_train=df_football[Target], \n",
    "                            feature_names=Predictors, \n",
    "                            target_name=Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree structure visualizations\n",
    "\n",
    "# viz_rmodel.view()\n",
    "viz_rmodel.view(orientation=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction path explanations\n",
    "x = df_football[Predictors].iloc[10]\n",
    "x\n",
    "viz_rmodel.view(x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_rmodel.view(show_just_path=True, x = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(viz_rmodel.explain_prediction_path(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz_rmodel.plot_importance(x, figsize=(3.5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leaf ratios\n",
    "viz_rmodel.leaf_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_rmodel.rtree_leaf_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_rmodel.node_stats(node_id=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost with linear learner base model (GBlinear)**- Have to use XGBoot non scikit learn functions to build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_train = xgb.DMatrix(data=X_train, label=y_train, enable_categorical= True)\n",
    "DM_test = xgb.DMatrix(data=X_test, label=y_test, enable_categorical = True)\n",
    "\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"booster\":\"gblinear\", \"objective\":\"reg:squarederror\"}\n",
    "\n",
    "# Define evaluation data\n",
    "eval_data = [(DM_train, 'train'), (DM_test, 'test')]\n",
    "\n",
    "\n",
    "# Train the model: xg_reg\n",
    "xg_gbl = xgb.train(params=params, dtrain=DM_train, evals =eval_data, num_boost_round=5)\n",
    "\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_gbl.predict(DM_test)\n",
    "\n",
    "# Calculate the error RMSE\n",
    "error = xg_gbl.eval(DM_test)\n",
    "print('Evaluation Error:', error)\n",
    "\n",
    "# Compute and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "# compute the rmse: rmse\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE %f:\" % (rmse))\n",
    "#Measuring Goodness of fit in Training data\n",
    "from sklearn import metrics\n",
    "print('Train R2 Value:',metrics.r2_score(y_train, xg_gbl.predict(DM_train)))\n",
    "#Measuring accuracy on Testing Data\n",
    "print('Accuracy Test',100- (np.mean(np.abs((y_test - preds) / y_test)) * 100))\n",
    "\n",
    "\n",
    "# # Plot the feature importance\n",
    "from matplotlib import pyplot\n",
    "# plt.figure(figsize=(10, 20))\n",
    "plot_importance(xg_gbl, max_num_features = 15)\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test, preds)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_trans = y_test.reshape(-1)\n",
    "residuals = y_test_trans - preds\n",
    "residuals\n",
    "# preds.shape\n",
    "# # y_test.shape\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(residuals, bins= 20)\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nil_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Perform cross-valdiation: cv_results\n",
    "cv_results = xgb.cv(dtrain=nil_dmatrix, params=params, nfold=4,\n",
    "                    num_boost_round=100, metrics='rmse', as_pandas=True, seed=42)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Extract and print final boosting round metric\n",
    "print((cv_results['test-rmse-mean']).tail(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nil_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Perform cross-valdiation: cv_results\n",
    "cv_results = xgb.cv(dtrain=nil_dmatrix, params=params, nfold=4,\n",
    "                    num_boost_round=100, metrics='mae', as_pandas=True, seed=42)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Extract and print final boosting round metric\n",
    "print((cv_results['test-mae-mean']).tail(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/parrt/dtreeviz/blob/master/notebooks/dtreeviz_xgboost_visualisations.ipynb\n",
    "\n",
    "#initialize dtreevizmodel (adaptor)\n",
    "\n",
    "viz_rmodel = dtreeviz.model(model=xg_reg2, tree_index=0, \n",
    "                            X_train=X, \n",
    "                            y_train=y, \n",
    "                            feature_names=Predictors, \n",
    "                            target_name=Target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finetune XGBoost Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('encoder', TargetEncoder()),\n",
    "    ('clf', XGBRegressor(random_state=8)) # can customize objective function with the objective parameter\n",
    "]\n",
    "pipe = Pipeline(steps=estimators)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Define the hyperparameter distributions\n",
    "\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': [100, 500, 900, 1100, 1500],\n",
    "    'max_depth': [2, 3, 5, 10, 15],\n",
    "    'learning_rate': [0.05, 0.1, 0.15, 0.20],\n",
    "    'min_child_weight': [1, 2, 3, 4]\n",
    "    }\n",
    "\n",
    "\n",
    "# Set up the random search with 5-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=XGBRegressor(),\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'r2_score',n_jobs = 5,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            \n",
    "            random_state=42)\n",
    "\n",
    "# Create the XGBoost model object\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_cv.fit(X_train,y_train)\n",
    "\n",
    "random_cv.best_estimator_\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", random_cv.best_params_)\n",
    "print(\"Best score: \", random_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset has 3 categorical featurs (NAME, STARCOLL, institution_name_short). XGBoost has the ability to internally deal with categoricals.Enable this feature by castingthe categorical columns into Pandas category data type (by default, they are treated as text columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text features\n",
    "cats = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "# Convert to Pandas category\n",
    "for col in cats:\n",
    "   X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split data into test and train (0.20 test)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "#Shuffle data given concern that dataset has athletes ordered by SKILL (but also look at skew later based on model performance)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost comes with its own class for storing datasets called DMatrix. It is a highly optimized class for memory and speed. That's why converting datasets into this format is a requirement for the native XGBoost API. Native API of XGBoost contains some excellent features that Scikit-Learn API doesn’t support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create regression matrices\n",
    "#class accepts both the training features and the labels- enable_categorical = True)\n",
    "dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "dtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a value for the objective parameter- RMSE, minimizes the square root of the squared sum of the differences between actual and predicted values. Objective functions and specified hyperparameters specified in params dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_boost_round =  number of boosting rounds. Hyperparameter to be tuned. Initally set to 100.\n",
    "#training dataset = dtrain_reg\n",
    "#function trains the XGBoost regression model with the specified hyperparameters and returns the trained model.\n",
    "#tree booster always outperforms the linear booster (which israrely used)\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "\n",
    "num_boost_round = 100\n",
    "model = xgb.train(\n",
    "   params=params,\n",
    "   dtrain=dtrain_reg,\n",
    "   num_boost_round=num_boost_round\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation** During boosting rounds, the model object has learned all the patterns of the training set. Perform testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(dtest_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "print(f\"RMSE of the base model: {rmse:.3f}\")\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "print(f\"MAE of the base model: {mae:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Validation Sets during Training** https://www.datacamp.com/tutorial/xgboost-in-python\n",
    "Use evaluation arrays that allow us to see model performance as it gets improved incrementally across boosting rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters again\n",
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "num_boost_round = 100\n",
    "\n",
    "#create list of two tupleshat each contain two elements. \n",
    "# #The first element is the array for the model to evaluate.\n",
    "#The second is the array’s name.\n",
    "\n",
    "evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]\n",
    "\n",
    "#Pass array to evals parameter of xgb.train to see model boosting performance after each round\n",
    "\n",
    "model = xgb.train(\n",
    "   params=params,\n",
    "   dtrain=dtrain_reg,\n",
    "   num_boost_round=num_boost_round,\n",
    "   evals=evals,\n",
    "   verbose_eval=10 # Every ten rounds   #forces XGBoost to print performance updates every vebose_eval rounds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At 100 boosting rounds validation-rsme reached at 60, although training continues to decrease\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying 5000 rounds with verbosity 250\n",
    "\n",
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "num_boost_round = 5000\n",
    "\n",
    "evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]\n",
    "\n",
    "\n",
    "model = xgb.train(\n",
    "   params=params,\n",
    "   dtrain=dtrain_reg,\n",
    "   num_boost_round=num_boost_round,\n",
    "   evals=evals,\n",
    "   verbose_eval=250\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Early Stopping** Forces XGBoost to watch the validation loss, and if it stops improving for a specified number of rounds, it automatically stops training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 10000\n",
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "\n",
    "\n",
    "evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]\n",
    "\n",
    "model = xgb.train(\n",
    "   params=params,\n",
    "   dtrain=dtrain_reg,\n",
    "   num_boost_round=num_boost_round,\n",
    "   evals=evals,\n",
    "   verbose_eval=50,\n",
    "   early_stopping_rounds=50  #Activiate early stopping\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training stopped after round 61 <br>\n",
    "**Perform K-Fold Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "num_boost_round = 1000\n",
    "\n",
    "results = xgb.cv(\n",
    "   params, \n",
    "   dtrain_reg,\n",
    "   num_boost_round=num_boost_round,\n",
    "   nfold=5,\n",
    "   early_stopping_rounds=20\n",
    ")\n",
    "\n",
    "#df containing each folds results\n",
    "results.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best score by taking the minimum of the test-rmse-mean column\n",
    "best_rmse = results['test-rmse-mean'].min()\n",
    "\n",
    "best_rmse\n",
    "print(f\"Best RMSE K-Fold CV: {best_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.scatter(y_test, predictions)\n",
    "# plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
    "# plt.xlabel('True Values')\n",
    "# plt.ylabel('Predicted Values')\n",
    "# plt.title('True vs Predicted Values')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance** Which features are most influential in making NIL prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(9,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_importance(model, ax=ax, height=0.6, importance_type=\"weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define hyperparameters\n",
    "# params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "\n",
    "#started with baseline parameters\n",
    "\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective': 'reg:squarederror',\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "\n",
    "num_boost_round = 999\n",
    "# params['eval_metric'] = \"mae\"\n",
    "\n",
    "# evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]\n",
    "\n",
    "model = xgb.train(\n",
    "    params = params,\n",
    "    dtrain =dtrain_reg,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtrain_reg, \"train\"),(dtest_reg, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "preds = model.predict(dtest_reg)\n",
    "y_true = y_test # True values\n",
    "\n",
    "print(\"Best Test MAE: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation with current parameters\n",
    "# params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "\n",
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain_reg,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'mae', 'rmse'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_mae = cv_results['test-mae-mean'].min()\n",
    "# best_mae\n",
    "\n",
    "best_rmse = cv_results['test-rmse-mean'].min()\n",
    "best_rmse\n",
    "print(f\"Best RMSE CV: {best_rmse:.3f}\")\n",
    "print(f\"Best MAE CV: {best_mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(9,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_importance(model, ax=ax, height=0.6, importance_type=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning max_depth and min_child_weight\n",
    "'''  max_depth = maximum number of nodes allowed from the root to the farthest leaf of a tree. \n",
    "                Deeper trees can model more complex relationships by adding more nodes, \n",
    "                but as we go deeper,splits become less relevant and are sometimes only due to noise,\n",
    "                causing the model to overfit. \n",
    "                min_child_weight = minimum weight (or number of samples if all samples have a weight of 1) \n",
    "                required in order to create a new node in the tree.\n",
    "                A smaller min_child_weight allows the algorithm to create children that \n",
    "                correspond to fewer samples, thus allowing for more complex trees, \n",
    "                but again, more likely to overfit. '''\n",
    "\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]\n",
    "\n",
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain_reg,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae', 'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "     # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update params\n",
    "params['max_depth'] = 10\n",
    "params['min_child_weight'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning subsample and colsample_bytree\n",
    "'''   Instead of using the whole training set every time, we can build a \n",
    "    tree on slightly different data at each step, \n",
    "    which makes it less likely to overfit to a single sample or feature.\n",
    "\n",
    "subsample =  the fraction of observations (the rows) to subsample at each step. \n",
    "By default it is set to 1 meaning that we use all rows.\n",
    "colsample_bytree = the fraction of features (the columns) to use. \n",
    "By default it is set to 1 meaning that we will use all features    '''\n",
    "\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain_reg,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "        \n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update params\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning  eta\n",
    "import time\n",
    "\n",
    "'''    eta = controls the learning rate. corresponds to the shrinkage of \n",
    "            the weights associated to features after each round/ defines the amount of \"correction\" \n",
    "            at each step\n",
    "            lower eta makes model more robust to overfitting.\n",
    "            Usually, the lower the learning rate, the best. \n",
    "            With lower eta,  need more boosting rounds, which takes more time to train, \n",
    "            sometimes for only marginal improvements\n",
    "\n",
    "\n",
    "'''\n",
    "time\n",
    "\n",
    "%time \n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "\n",
    "    # Update parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    %time \n",
    "    cv_results = xgb.cv(\n",
    "            params,\n",
    "            dtrain_reg,\n",
    "            num_boost_round=num_boost_round,\n",
    "            seed=42,\n",
    "            nfold=5,\n",
    "            metrics=['mae'],\n",
    "            early_stopping_rounds=10\n",
    "          )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = .005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final params dictionary\n",
    "params\n",
    "{'colsample_bytree': 1.0,\n",
    " 'eta': 0.005,\n",
    "'eval_metric': {'mae','rmse'},\n",
    "'max_depth': 10,\n",
    "'min_child_weight': 5,\n",
    "'objective': 'reg:tree',\n",
    "'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train model with new params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior\n",
    "# num_boost_round = 100\n",
    "# model = xgb.train(\n",
    "#    params=params,\n",
    "#    dtrain=dtrain_reg,\n",
    "#    num_boost_round=num_boost_round,\n",
    "# ) \n",
    "\n",
    "\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain_reg,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest_reg, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "print(\"Best MAE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best rounds known, take out early stopping\n",
    "params\n",
    "{'colsample_bytree': 1.0,\n",
    " 'eta': 0.005,\n",
    "'eval_metric': {'mae','rmse'},\n",
    "'max_depth': 10,\n",
    "'min_child_weight': 5,\n",
    "'objective': 'reg:tree',\n",
    "'subsample': 0.8}\n",
    "\n",
    "num_boost_round = model.best_iteration + 1\n",
    "\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain_reg,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest_reg, \"Test\")]\n",
    ")\n",
    "\n",
    "predictions = best_model.predict(dtest_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain_reg,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'mae', 'rmse'},\n",
    "  \n",
    ")\n",
    "\n",
    "#df containing each folds results\n",
    "cv_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_mae = cv_results['test-mae-mean'].min()\n",
    "# best_mae\n",
    "\n",
    "best_rmse = cv_results['test-rmse-mean'].min()\n",
    "best_rmse\n",
    "print(f\"Best RMSE CV: {best_rmse:.3f}\")\n",
    "print(f\"Best MAE CV: {best_mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(best_model.predict(dtest_reg), y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOT getting same MAE as in last round (48733)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning with GridSearchCV**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "%time\n",
    "\n",
    "params = {\n",
    "    'max_depth' : [8,9,10, 11, 12],\n",
    "    'min_child_weight': [5,6,7,8],\n",
    "    'subsample':[0.6,0.7, 0.8, 0.9, 1.0],\n",
    "    'n_estimators': [50,100],\n",
    "    'max_depth': [None, 3, 5, 7, 9],\n",
    "    'eta': [.3, .2, .1, .05, .01, .005]\n",
    "    }\n",
    "grid_search = GridSearchCV(xgb.XGBRegressor(), params, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test  R2 Score : %.2f\"%grid_search.score(X_test, y_test))\n",
    "print(\"Train R2 Score : %.2f\"%grid_search.score(X_train, y_train))\n",
    "\n",
    "print(\"Best Params : \", grid_search.best_params_)\n",
    "# print(\"Feature Importances : \")\n",
    "# # pd.DataFrame([grid_search.best_estimator_.feature_importances_], columns=df_football.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = pd.DataFrame(grid_search.cv_results_)\n",
    "print(\"Grid Search Size : \", grid_search_results.shape)\n",
    "grid_search_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using select features of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['GRADE', 'AGE', 'SKILL',  'NUMOFF', 'POS',\n",
    "       'HEIGHT_IN', 'WEIGHT_LBS', 'COLLDIST_MI', 'NILVAL_LONG_USD',\n",
    "       'INSTA_LONG', 'TWIT_LONG', 'TIK_LONG', 'TOT_FOL', \n",
    "       'EXP_MONTHS',  \n",
    "       'ClassificationCode', 'REV_MEN', 'EXP_MEN']\n",
    "df_fb_select =df_football[columns].copy()\n",
    "\n",
    "# df_fb_select.shape  #(1263,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature and target arrays\n",
    "X, y = df_fb_select.drop('NILVAL_LONG_USD', axis=1), df_fb_select[['NILVAL_LONG_USD']]\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Create regression matrices\n",
    "#class accepts both the training features and the labels- enable_categorical = True)\n",
    "dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "dtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical=True)\n",
    "\n",
    "# Define hyperparameters\n",
    "# params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "params\n",
    "{'colsample_bytree': 1.0,\n",
    " 'eta': 0.005,\n",
    "'eval_metric': {'mae','rmse'},\n",
    "'max_depth': 10,\n",
    "'min_child_weight': 5,\n",
    "'objective': 'reg:tree',\n",
    "'subsample': 0.8}\n",
    "\n",
    "num_boost_round = 100\n",
    "\n",
    "#train model \n",
    "model = xgb.train(\n",
    "   params=params,\n",
    "   dtrain=dtrain_reg,\n",
    "   num_boost_round=num_boost_round,\n",
    "   # evals=[(dtrain_reg, \"train\"), (dtest_reg, \"test\")]\n",
    "   \n",
    ")\n",
    "#make predictions\n",
    "preds = model.predict(dtest_reg)\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "print(\"Train RMSE : \",model.eval(dtrain_reg))\n",
    "print(\"Test  RMSE : \",model.eval(dtest_reg))\n",
    "print(\"Train  R2 Score : %.2f\"%r2_score(y_train, model.predict(dtrain_reg)))\n",
    "print(\"Test R2 Score : %.2f\"%r2_score(y_test, model.predict(dtest_reg)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({ \"Actuals\":y_test[:10], \"Prediction\":model.predict(dtest_reg)[:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"ggplot\"):\n",
    "    fig = plt.figure(figsize=(9,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    xgb.plotting.plot_importance(model, ax=ax, height=0.6, importance_type=\"weight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
